{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc7b3cb4-9b4e-408e-8a73-ed3ea15cc415",
   "metadata": {},
   "source": [
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c21d8179-3660-4418-a6fe-1c4c4ae46e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8de0789-8efb-42f3-86e9-b9a277c3b343",
   "metadata": {},
   "source": [
    "## Define the Sparse Autoencoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff45048e-e427-4945-827f-92c5ba2f0dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sparse Autoencoder definition\n",
    "class SparseAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, sparsity_weight=1e-3):\n",
    "        super(SparseAutoencoder, self).__init__()\n",
    "        self.encoder = nn.Linear(input_dim, hidden_dim)\n",
    "        self.decoder = nn.Linear(hidden_dim, input_dim)\n",
    "        self.sparsity_weight = sparsity_weight\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = F.relu(self.encoder(x))\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded, encoded\n",
    "\n",
    "    def sparsity_loss(self, encoded):\n",
    "        sparsity_loss = torch.mean(torch.abs(encoded))\n",
    "        return self.sparsity_weight * sparsity_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc00d69-66b3-44d6-aab7-445262b52ce0",
   "metadata": {},
   "source": [
    "## Prepare the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "327c03f2-8197-4c47-903e-084497f9522e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (111, 35)\n",
      "y_train shape: (111, 1)\n",
      "X_test shape: (54, 35)\n"
     ]
    }
   ],
   "source": [
    "# Define the path where the data is located\n",
    "data_path = r\"C:/Users/divyas/Documents/hackathons/CMI_PB/Tasks/Task_IGg_PT/Data_Task_IGg_PT/\"\n",
    "\n",
    "# Load the datasets using the data path\n",
    "X_train = pd.read_csv(data_path + \"abtiter_data_X_train.csv\", index_col=0)\n",
    "y_train = pd.read_csv(data_path + \"abtiter_data_y_train.csv\", index_col=0)\n",
    "X_test = pd.read_csv(data_path + \"abtiter_data_X_test.csv\", index_col=0)\n",
    "\n",
    "# Display the shapes of the datasets\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851856be-38f9-4244-acaf-8e1734f26c9b",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70e86773-01c6-45b5-9955-8353a986f70f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             IgG_PRN    IgG_FHA   IgG1_PT  IgG1_PRN  IgG1_FHA  IgG1_FIM2/3  \\\n",
      "subject_id                                                                   \n",
      "1           2.602350  34.050956  7.334714  2.174783  3.013252     1.188744   \n",
      "3           7.652635   1.096457  1.424098  3.161591  1.287515     0.322658   \n",
      "4           5.670403   1.048276  3.888604  2.591155  1.269821     2.621216   \n",
      "5           5.268274   0.084437  7.456313  2.760065  2.864834     7.487345   \n",
      "6           0.090176   0.379290  0.084132  0.025479  0.654192     0.681225   \n",
      "\n",
      "             IgG1_TT   IgG1_DT   IgG1_OVA   IgG2_PT  ...   IgG3_OVA  \\\n",
      "subject_id                                           ...              \n",
      "1           1.428852  2.389153   0.665203  1.000000  ...   1.865388   \n",
      "3           1.377390  1.523941  33.771912  1.000000  ...   1.119233   \n",
      "4           1.675259  2.022924   5.777047  4.269877  ...   1.000000   \n",
      "5           1.537432  2.250237   4.130732  6.070427  ...   5.446934   \n",
      "6           0.874920  0.369367  10.452881  1.000000  ...  13.206949   \n",
      "\n",
      "              IgG4_PT   IgG4_PRN   IgG4_FHA  IgG4_FIM2/3   IgG4_TT   IgG4_DT  \\\n",
      "subject_id                                                                     \n",
      "1            1.061706  11.673594   0.880611     0.980223  3.290050  1.232849   \n",
      "3            1.000000   0.733287   0.057114     0.980223  0.024820  0.003253   \n",
      "4            6.582579   3.261863   1.089128    40.303354  1.635454  0.634256   \n",
      "5           44.804003   1.112574  24.353645     4.855024  0.920018  1.879391   \n",
      "6            1.000000   0.208993   0.984870     1.529665  3.565218  0.676574   \n",
      "\n",
      "            IgG4_OVA  infancy_vac  biological_sex  \n",
      "subject_id                                         \n",
      "1           2.622675            0               0  \n",
      "3           0.053981            0               0  \n",
      "4           2.021985            0               1  \n",
      "5           1.569320            0               1  \n",
      "6           7.648106            0               0  \n",
      "\n",
      "[5 rows x 32 columns]\n",
      "             IgG_PRN   IgG_FHA    IgG1_PT  IgG1_PRN  IgG1_FHA  IgG1_FIM2/3  \\\n",
      "subject_id                                                                   \n",
      "142         0.066482  0.102288   0.452381  1.343446  0.637104     1.250859   \n",
      "146         3.039959  2.687800  27.488095  3.248061  2.481587     0.508973   \n",
      "163         0.052871  0.002726   0.510791  0.025011  0.010421     0.008366   \n",
      "124         1.053969  0.299007   1.416667  0.911267  0.298782     0.068729   \n",
      "134         1.344032  0.987074   0.904762  1.208517  1.225409     1.037801   \n",
      "\n",
      "             IgG1_TT   IgG1_DT  IgG1_OVA   IgG2_PT  ...  IgG3_OVA  IgG4_PT  \\\n",
      "subject_id                                          ...                      \n",
      "142         0.137712  0.252301  0.215054  0.419355  ...  0.991379  0.43750   \n",
      "146         0.056218  0.830831  0.309677  0.709677  ...  0.724138  0.65625   \n",
      "163         0.291480  0.334586  0.395062  0.666667  ...  1.615385  0.56250   \n",
      "124         0.525460  1.147328  0.572043  0.870968  ...  0.672414  1.40625   \n",
      "134         2.272647  1.163639  1.668817  1.032258  ...  0.637931  0.93750   \n",
      "\n",
      "             IgG4_PRN  IgG4_FHA  IgG4_FIM2/3   IgG4_TT   IgG4_DT  IgG4_OVA  \\\n",
      "subject_id                                                                   \n",
      "142          0.454545  0.275735     0.630000  0.049354  0.388167  0.050901   \n",
      "146          1.636364  0.107843     0.800000  0.056404  3.195280  0.027928   \n",
      "163          0.140719  0.143443     0.472727  0.257426  0.079650  0.295082   \n",
      "124         16.083333  3.752451     1.040000  8.465335  8.604651  0.111712   \n",
      "134          0.833333  0.276961     0.840000  0.291422  0.094391  2.032207   \n",
      "\n",
      "            infancy_vac  biological_sex  \n",
      "subject_id                               \n",
      "142                   1               0  \n",
      "146                   0               1  \n",
      "163                   0               0  \n",
      "124                   1               1  \n",
      "134                   0               1  \n",
      "\n",
      "[5 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "# Mapping categorical columns to numerical values\n",
    "X_train['infancy_vac'] = X_train['infancy_vac'].map({'wP': 0, 'aP': 1})\n",
    "X_train['biological_sex'] = X_train['biological_sex'].map({'Female': 0, 'Male': 1})\n",
    "\n",
    "# Dropping the unnecessary columns\n",
    "X_train = X_train.drop(columns=['dataset', 'timepoint', 'date_of_boost'])\n",
    "\n",
    "# Display the modified dataframe\n",
    "print(X_train.head())\n",
    "\n",
    "X_test['infancy_vac'] = X_test['infancy_vac'].map({'wP': 0, 'aP': 1})\n",
    "X_test['biological_sex'] = X_test['biological_sex'].map({'Female': 0, 'Male': 1})\n",
    "\n",
    "# Dropping the unnecessary columns\n",
    "X_test = X_test.drop(columns=['dataset', 'timepoint', 'date_of_boost'])\n",
    "\n",
    "# Display the modified dataframe\n",
    "print(X_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5df54297-76ac-45b4-8402-f7aedd5a3936",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32)\n",
    "\n",
    "batch_size = 32\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataset = TensorDataset(X_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b0ad02a-3667-4ebc-9c1a-92cf93742b6a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'random_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m train_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m0.8\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataset))\n\u001b[0;32m      4\u001b[0m val_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataset) \u001b[38;5;241m-\u001b[39m train_size\n\u001b[1;32m----> 5\u001b[0m train_dataset, val_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mrandom_split\u001b[49m(dataset, [train_size, val_size])\n\u001b[0;32m      7\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m\n\u001b[0;32m      8\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(train_dataset, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'random_split' is not defined"
     ]
    }
   ],
   "source": [
    "# Create dataset and split into train and val\n",
    "dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925d2340-5597-4aa2-b5cf-e6115539e290",
   "metadata": {},
   "source": [
    "## Training the Sparse Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac43a484-02ee-4dea-b7d0-b96bd7e1cf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = X_train.shape[1]\n",
    "hidden_dim = 64  # Adjust for dimensionality reduction\n",
    "\n",
    "model = SparseAutoencoder(input_dim=input_dim, hidden_dim=hidden_dim)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "num_epochs = 50\n",
    "\n",
    "train_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0.0\n",
    "    for batch_data, _ in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        reconstructed, encoded = model(batch_data)\n",
    "        reconstruction_loss = F.mse_loss(reconstructed, batch_data)\n",
    "        sparsity_loss = model.sparsity_loss(encoded)\n",
    "        total_loss = reconstruction_loss + sparsity_loss\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += total_loss.item()\n",
    "    avg_epoch_loss = epoch_loss / len(train_loader)\n",
    "    train_losses.append(avg_epoch_loss)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_epoch_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124e25e8-60ff-4610-9a7d-9c7d072d236a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1, num_epochs + 1), train_losses, label='Training Loss')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Loss for Sparse Autoencoder\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd6d487-fc55-4231-929d-1847f4093aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract embeddings for training data\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    _, X_train_encoded = model(X_train_tensor)\n",
    "    _, X_test_encoded = model(X_test_tensor)\n",
    "\n",
    "# Convert embeddings to numpy for regression\n",
    "X_train_encoded_np = X_train_encoded.numpy()\n",
    "X_test_encoded_np = X_test_encoded.numpy()\n",
    "y_train_np = y_train_tensor.numpy().ravel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21aa291d-686a-4c91-a0d3-18cdd4a87260",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train_encoded_np, y_train_np)\n",
    "y_pred_train = regressor.predict(X_train_encoded_np)\n",
    "\n",
    "# Predict on test data (if labels available, use y_test for evaluation)\n",
    "y_pred_test = regressor.predict(X_test_encoded_np)\n",
    "train_rmse = mean_squared_error(y_train_np, y_pred_train, squared=False)\n",
    "print(f\"Training RMSE: {train_rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11475b81-184b-4b1f-8911-8f1dae2dce61",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_train_np, y_pred_train, alpha=0.7)\n",
    "plt.xlabel(\"Actual IgG_PT\")\n",
    "plt.ylabel(\"Predicted IgG_PT\")\n",
    "plt.title(\"Training Set: Predicted vs Actual IgG_PT\")\n",
    "plt.plot([y_train_np.min(), y_train_np.max()], [y_train_np.min(), y_train_np.max()], 'k--')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cc7e5d-3e86-45ec-84d5-5f85d235a231",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
